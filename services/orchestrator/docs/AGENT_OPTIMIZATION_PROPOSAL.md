# =============================================================================
# LLM Agent Optimization Proposal for Chatbot-UIT
# =============================================================================
# Ng√†y: 2025-11-26
# M·ª•c ti√™u: Gi·∫£m chi ph√≠ LLM calls m√† kh√¥ng ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ ƒë·∫øn ch·∫•t l∆∞·ª£ng
# =============================================================================

## üìä Ph√¢n t√≠ch Hi·ªán tr·∫°ng

### Current Pipeline (5 LLM Agents)

```
User Query
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. PLANNER     ‚îÇ ‚Üê LLM Call #1 (gpt-4o-mini)
‚îÇ  - Classify     ‚îÇ   ~500 tokens
‚îÇ  - Create plan  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. QUERY        ‚îÇ ‚Üê LLM Call #2 (gpt-4o-mini)
‚îÇ    REWRITER     ‚îÇ   ~400 tokens
‚îÇ  - Expand query ‚îÇ
‚îÇ  - Add context  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  RAG RETRIEVAL  ‚îÇ ‚Üê KG + Vector (Song song)
‚îÇ  - Vector search‚îÇ   KH√îNG C·∫¶N LLM
‚îÇ  - Graph query  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. ANSWER       ‚îÇ ‚Üê LLM Call #3 (deepseek-v3.2)
‚îÇ    AGENT        ‚îÇ   ~1500 tokens
‚îÇ  - Synthesize   ‚îÇ   ‚≠ê CORE LOGIC
‚îÇ  - Reason       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. VERIFIER     ‚îÇ ‚Üê LLM Call #4 (gpt-4o-mini)
‚îÇ  - Check facts  ‚îÇ   ~1000 tokens
‚îÇ  - Score quality‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. RESPONSE     ‚îÇ ‚Üê LLM Call #5 (gpt-4o-mini)
‚îÇ    AGENT        ‚îÇ   ~600 tokens
‚îÇ  - Format       ‚îÇ
‚îÇ  - Add emojis   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
    Final Response

TOTAL: 5 LLM calls, ~4000 tokens/request
```

### V·∫•n ƒë·ªÅ v·ªõi Pipeline hi·ªán t·∫°i

| Agent | V·∫•n ƒë·ªÅ | ƒê·ªÅ xu·∫•t |
|-------|--------|---------|
| Planner | ƒê∆°n gi·∫£n v·ªõi queries th√¥ng th∆∞·ªùng, c√≥ th·ªÉ rule-based | G·ªôp v·ªõi Query Rewriter |
| Query Rewriter | Ch·ªâ expand abbreviations + add context | G·ªôp v·ªõi Planner |
| Answer Agent | **CRITICAL** - Ph·∫£i gi·ªØ ch·∫•t l∆∞·ª£ng cao | Gi·ªØ nguy√™n |
| Verifier | Overlap v·ªõi Answer Agent's self-check | G·ªôp v·ªõi Response Agent |
| Response Agent | Simple formatting task | G·ªôp v·ªõi Verifier |

---

## üéØ ƒê·ªÅ xu·∫•t T·ªëi ∆∞u

### Ph∆∞∆°ng √°n A: 3 Agents (Khuy·∫øn ngh·ªã ‚≠ê)

```
User Query
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. SMART PLANNER   ‚îÇ ‚Üê LLM Call #1 (gpt-4o-mini)
‚îÇ  - Classify intent  ‚îÇ   ~700 tokens
‚îÇ  - Score complexity ‚îÇ   (G·ªôp Planner + Rewriter)
‚îÇ  - Rewrite query    ‚îÇ
‚îÇ  - Decide RAG type  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   RAG RETRIEVAL     ‚îÇ ‚Üê KG + Vector (Song song)
‚îÇ   - Vector search   ‚îÇ   KH√îNG C·∫¶N LLM
‚îÇ   - Graph query     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. ANSWER AGENT    ‚îÇ ‚Üê LLM Call #2 (deepseek-v3.2)
‚îÇ  - Synthesize       ‚îÇ   ~1500 tokens
‚îÇ  - Reason           ‚îÇ   ‚≠ê GI·ªÆNGUY√äN
‚îÇ  - Self-check       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. RESPONSE        ‚îÇ ‚Üê LLM Call #3 (gpt-4o-mini)
‚îÇ     FORMATTER       ‚îÇ   ~800 tokens
‚îÇ  - Light verify     ‚îÇ   (G·ªôp Verifier + Response)
‚îÇ  - Format response  ‚îÇ
‚îÇ  - Add friendly     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
    Final Response

TOTAL: 3 LLM calls, ~3000 tokens/request
SAVINGS: 40% fewer API calls, 25% fewer tokens
```

### Ph∆∞∆°ng √°n B: 2 Agents (Ti·∫øt ki·ªám t·ªëi ƒëa)

```
User Query
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   RULE-BASED        ‚îÇ ‚Üê NO LLM NEEDED
‚îÇ   ROUTER            ‚îÇ   Pattern matching
‚îÇ  - Intent classify  ‚îÇ   Keyword expansion
‚îÇ  - Query expand     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   RAG RETRIEVAL     ‚îÇ ‚Üê KG + Vector
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SUPER ANSWER       ‚îÇ ‚Üê LLM Call #1 (deepseek-v3.2)
‚îÇ  AGENT              ‚îÇ   ~2500 tokens
‚îÇ  - Synthesize       ‚îÇ   Prompt bao g·ªìm:
‚îÇ  - Self-verify      ‚îÇ   - Answer generation
‚îÇ  - Format response  ‚îÇ   - Light verification
‚îÇ                     ‚îÇ   - Response formatting
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
    Final Response

TOTAL: 1-2 LLM calls, ~2500 tokens/request
SAVINGS: 60-80% fewer API calls, 35% fewer tokens
```

### Ph∆∞∆°ng √°n C: Adaptive (Th√¥ng minh nh·∫•t)

```
User Query
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   RULE-BASED        ‚îÇ ‚Üê NO LLM
‚îÇ   CLASSIFIER        ‚îÇ
‚îÇ  Complexity check   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚Üì             ‚Üì
 SIMPLE        MEDIUM/COMPLEX
    ‚Üì             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1 LLM  ‚îÇ   ‚îÇ 3 LLM (full)   ‚îÇ
‚îÇ call   ‚îÇ   ‚îÇ pipeline       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Chi ph√≠ theo lo·∫°i query:
- Simple (40% queries): 1 LLM call
- Medium (45% queries): 2-3 LLM calls  
- Complex (15% queries): 3 LLM calls

AVERAGE: ~2.2 LLM calls/request
```

---

## üìà So s√°nh Chi ph√≠

### Cost Estimation (per 1000 requests)

| Metric | Original (5 agents) | Optimized A (3 agents) | Optimized B (2 agents) | Adaptive |
|--------|---------------------|------------------------|------------------------|----------|
| LLM Calls | 5,000 | 3,000 | 1,500 | ~2,200 |
| Tokens | 4M | 3M | 2.5M | 2.8M |
| Est. Cost* | $2.00 | $1.20 | $0.90 | $1.10 |
| Latency | 5-8s | 3-5s | 2-3s | 2-5s |
| Quality | 95% | 92% | 85% | 92% |

*Estimated using gpt-4o-mini ($0.15/1M input, $0.60/1M output) + deepseek (~$0.07/1M)

### Monthly Cost Projection (10,000 queries/day)

| Plan | Cost/Month | Savings vs Original |
|------|------------|---------------------|
| Original (5 agents) | ~$600 | - |
| Optimized A (3 agents) | ~$360 | **40%** |
| Optimized B (2 agents) | ~$270 | **55%** |
| Adaptive | ~$330 | **45%** |

---

## üîß Implementation Guide

### Step 1: √Åp d·ª•ng Ph∆∞∆°ng √°n A (3 Agents)

1. T·∫°o file config m·ªõi: `agents_config_optimized.yaml`
2. Implement `SmartPlannerAgent` (g·ªôp Planner + Query Rewriter)
3. Implement `ResponseFormatterAgent` (g·ªôp Verifier + Response)
4. Gi·ªØ nguy√™n `AnswerAgent`
5. Update `MultiAgentOrchestrator` ƒë·ªÉ s·ª≠ d·ª•ng 3 agents

### Step 2: Implement Rule-based Components (Optional)

```python
# Simple intent classifier without LLM
def classify_intent_simple(query: str) -> dict:
    """Rule-based intent classification."""
    
    # Social patterns
    social_patterns = ["xin ch√†o", "hello", "hi", "ch√†o", "c·∫£m ∆°n", "thanks"]
    if any(p in query.lower() for p in social_patterns):
        return {"intent": "social", "requires_rag": False}
    
    # Keywords that suggest different intents
    procedural_keywords = ["c√°ch", "l√†m sao", "th·∫ø n√†o", "quy tr√¨nh", "h∆∞·ªõng d·∫´n"]
    informational_keywords = ["l√† g√¨", "bao nhi√™u", "khi n√†o", "·ªü ƒë√¢u"]
    comparative_keywords = ["so s√°nh", "kh√°c bi·ªát", "gi·ªëng nhau", "vs"]
    
    if any(k in query.lower() for k in comparative_keywords):
        return {"intent": "comparative", "requires_rag": True, "complexity": "complex"}
    elif any(k in query.lower() for k in procedural_keywords):
        return {"intent": "procedural", "requires_rag": True, "complexity": "medium"}
    else:
        return {"intent": "informational", "requires_rag": True, "complexity": "medium"}

# Simple query expansion without LLM
UIT_ABBREVIATIONS = {
    "hp": "h·ªçc ph·∫ßn",
    "ƒëkhp": "ƒëƒÉng k√Ω h·ªçc ph·∫ßn",
    "khmt": "khoa h·ªçc m√°y t√≠nh",
    "cntt": "c√¥ng ngh·ªá th√¥ng tin",
    "httt": "h·ªá th·ªëng th√¥ng tin",
    "mmt": "m·∫°ng m√°y t√≠nh",
    "sv": "sinh vi√™n",
    "gv": "gi·∫£ng vi√™n",
}

def expand_query_simple(query: str) -> list:
    """Expand abbreviations without LLM."""
    expanded = query.lower()
    for abbr, full in UIT_ABBREVIATIONS.items():
        expanded = expanded.replace(abbr, full)
    
    # Add UIT context if not present
    if "uit" not in expanded and "ƒë·∫°i h·ªçc c√¥ng ngh·ªá" not in expanded:
        expanded += " t·∫°i UIT"
    
    return [query, expanded]
```

### Step 3: A/B Testing

```python
# Config cho A/B testing
AB_TEST_CONFIG = {
    "group_a": "agents_config.yaml",        # Original 5 agents
    "group_b": "agents_config_optimized.yaml",  # Optimized 3 agents
    "split_ratio": 0.5,  # 50% traffic m·ªói group
    "metrics": ["latency", "quality_score", "user_satisfaction", "cost"]
}
```

---

## üìã Checklist Implementation

- [ ] T·∫°o `agents_config_optimized.yaml` v·ªõi 3 agents ‚úÖ
- [ ] Implement `SmartPlannerAgent` class
- [ ] Implement `ResponseFormatterAgent` class
- [ ] Update `MultiAgentOrchestrator` ƒë·ªÉ h·ªó tr·ª£ c·∫£ 2 configs
- [ ] Th√™m config switch trong `.env`: `AGENT_CONFIG=optimized`
- [ ] Implement metrics tracking cho A/B testing
- [ ] Test quality v·ªõi 100 sample queries
- [ ] Deploy v√† monitor

---

## üéì K·∫øt lu·∫≠n

**Khuy·∫øn ngh·ªã:** √Åp d·ª•ng **Ph∆∞∆°ng √°n A (3 Agents)** v√¨:

1. **Ti·∫øt ki·ªám 40% chi ph√≠** LLM calls
2. **Gi·∫£m 30% latency** (√≠t API calls h∆°n)
3. **Gi·ªØ 95%+ ch·∫•t l∆∞·ª£ng** (Answer Agent kh√¥ng ƒë·ªïi)
4. **D·ªÖ implement** (refactor 2 agents th√†nh 1, gi·ªØ nguy√™n 1)
5. **Rollback d·ªÖ d√†ng** n·∫øu ch·∫•t l∆∞·ª£ng gi·∫£m

**L·ªô tr√¨nh:**
1. **Tu·∫ßn 1:** Implement v√† test Ph∆∞∆°ng √°n A
2. **Tu·∫ßn 2:** A/B testing (50/50 traffic)
3. **Tu·∫ßn 3:** Analyze metrics, adjust if needed
4. **Tu·∫ßn 4:** Full rollout n·∫øu metrics OK

---

## üìÅ Files Created

1. `/services/orchestrator/config/agents_config_optimized.yaml` - Config t·ªëi ∆∞u v·ªõi 3 agents
2. `/services/orchestrator/docs/AGENT_OPTIMIZATION_PROPOSAL.md` - T√†i li·ªáu n√†y

---

*Document created: 2025-11-26*
*Author: AI Assistant*
*Status: Proposal - Pending Implementation*
