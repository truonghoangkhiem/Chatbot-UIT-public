#!/usr/bin/env python3
"""
Comprehensive test for optimized 3-agent pipeline.
Tests: SmartPlannerAgent, AnswerAgent, ResponseFormatterAgent
"""

import asyncio
import sys
import os
from pathlib import Path
from dotenv import load_dotenv

# Load .env file first
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(env_path)

# Add the app directory to Python path
sys.path.append('/home/kien/Kien/study/SE363.Q11/Chatbot-UIT/services/orchestrator')

from app.adapters.openrouter_adapter import OpenRouterAdapter
from app.core.domain import AgentRequest, ConversationContext


async def test_smart_planner_agent():
    """
    Test SmartPlannerAgent - Merged Planner + Query Rewriter.
    Handles: intent classification, complexity scoring, query rewriting in single LLM call.
    """
    print("ğŸ§  Testing Smart Planner Agent (merged planner + query rewriter)...")
    
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        print("âŒ API key not found!")
        return False
    
    try:
        adapter = OpenRouterAdapter(api_key=api_key, timeout=None)
        
        context = ConversationContext(
            session_id="test-smart-planner",
            messages=[],
            system_prompt="""Báº¡n lÃ  SmartPlannerAgent cho há»‡ thá»‘ng Chatbot-UIT.
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ :
1. PhÃ¢n loáº¡i intent cá»§a cÃ¢u há»i (academic, administrative, general)
2. ÄÃ¡nh giÃ¡ Ä‘á»™ phá»©c táº¡p (1-10)
3. Viáº¿t láº¡i cÃ¢u há»i tá»‘i Æ°u cho RAG search
4. XÃ¡c Ä‘á»‹nh cáº§n KG vÃ /hoáº·c Vector search

Tráº£ lá»i báº±ng JSON format:
{
    "intent": "academic|administrative|general",
    "complexity": 1-10,
    "rewritten_queries": ["query1", "query2"],
    "use_knowledge_graph": true/false,
    "use_vector_search": true/false,
    "reasoning": "brief explanation"
}"""
        )
        
        request = AgentRequest(
            prompt="TÃ´i muá»‘n tÃ¬m hiá»ƒu vá» há»c phÃ­ vÃ  cÃ¡ch Ä‘Äƒng kÃ½ há»c pháº§n táº¡i UIT",
            context=context,
            model="mistralai/mistral-7b-instruct:free",
            temperature=0.1,
            max_tokens=500
        )
        
        response = await adapter.generate_response(request)
        
        print(f"âœ… Smart Planner Agent Response:")
        print(f"Model: {response.model_used}")
        print(f"Content: {response.content[:500]}...")
        print(f"Tokens: {response.tokens_used}")
        
        await adapter.close()
        return True
        
    except Exception as e:
        print(f"âŒ Smart Planner Agent Error: {e}")
        return False


async def test_answer_agent():
    """
    Test AnswerAgent - Core reasoning agent.
    Generates answers based on RAG context.
    """
    print("\nğŸ’¬ Testing Answer Agent...")
    
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        print("âŒ API key not found!")
        return False
    
    try:
        adapter = OpenRouterAdapter(api_key=api_key, timeout=None)
        
        # Simulate RAG context
        rag_context = [
            "Há»c phÃ­ táº¡i Äáº¡i há»c CÃ´ng nghá»‡ ThÃ´ng tin (UIT) nÄƒm 2024: Sinh viÃªn cÃ´ng láº­p: 756.000 VNÄ/tÃ­n chá»‰.",
            "Thá»i gian Ä‘Äƒng kÃ½ há»c pháº§n: ThÆ°á»ng vÃ o thÃ¡ng 7-8 cho há»c ká»³ 1, thÃ¡ng 12-1 cho há»c ká»³ 2.",
            "Sinh viÃªn cáº§n Ä‘Äƒng nháº­p vÃ o há»‡ thá»‘ng Portal Ä‘á»ƒ Ä‘Äƒng kÃ½ há»c pháº§n trá»±c tuyáº¿n."
        ]
        
        context = ConversationContext(
            session_id="test-answer",
            messages=[],
            system_prompt=f"""Báº¡n lÃ  Answer Agent chuyÃªn tráº£ lá»i cÃ¢u há»i dá»±a trÃªn context Ä‘Æ°á»£c cung cáº¥p.
Sá»­ dá»¥ng thÃ´ng tin sau Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c vÃ  há»¯u Ã­ch:

CONTEXT:
{chr(10).join(rag_context)}

Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, tá»± nhiÃªn vÃ  thÃ¢n thiá»‡n."""
        )
        
        request = AgentRequest(
            prompt="Há»c phÃ­ UIT bao nhiÃªu tiá»n? VÃ  lÃ m tháº¿ nÃ o Ä‘á»ƒ Ä‘Äƒng kÃ½ há»c pháº§n?",
            context=context,
            model="google/gemma-2-9b-it:free",
            temperature=0.7,
            max_tokens=400
        )
        
        response = await adapter.generate_response(request)
        
        print(f"âœ… Answer Agent Response:")
        print(f"Model: {response.model_used}")
        print(f"Answer: {response.content}")
        print(f"Tokens: {response.tokens_used}")
        
        await adapter.close()
        return True
        
    except Exception as e:
        print(f"âŒ Answer Agent Error: {e}")
        return False


async def test_response_formatter_agent():
    """
    Test ResponseFormatterAgent - Merged Verifier + Response Agent.
    Handles: verification + formatting in single LLM call.
    """
    print("\nğŸ“ Testing Response Formatter Agent (merged verifier + response)...")
    
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        print("âŒ API key not found!")
        return False
    
    try:
        adapter = OpenRouterAdapter(api_key=api_key, timeout=None)
        
        raw_answer = """Há»c phÃ­ táº¡i UIT nÄƒm 2024 lÃ  756.000 VNÄ/tÃ­n chá»‰ cho sinh viÃªn cÃ´ng láº­p. 
Äá»ƒ Ä‘Äƒng kÃ½ há»c pháº§n, sinh viÃªn cáº§n Ä‘Äƒng nháº­p vÃ o há»‡ thá»‘ng Portal vÃ o thá»i gian quy Ä‘á»‹nh 
(thÃ¡ng 7-8 cho há»c ká»³ 1, thÃ¡ng 12-1 cho há»c ká»³ 2)."""

        rag_context = [
            "Há»c phÃ­ táº¡i Äáº¡i há»c CÃ´ng nghá»‡ ThÃ´ng tin (UIT) nÄƒm 2024: Sinh viÃªn cÃ´ng láº­p: 756.000 VNÄ/tÃ­n chá»‰.",
            "Thá»i gian Ä‘Äƒng kÃ½ há»c pháº§n: ThÆ°á»ng vÃ o thÃ¡ng 7-8 cho há»c ká»³ 1, thÃ¡ng 12-1 cho há»c ká»³ 2."
        ]
        
        context = ConversationContext(
            session_id="test-response-formatter",
            messages=[],
            system_prompt=f"""Báº¡n lÃ  ResponseFormatterAgent cho há»‡ thá»‘ng Chatbot-UIT.
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ :
1. XÃ¡c minh cÃ¢u tráº£ lá»i vá»›i RAG context
2. ÄÃ¡nh giÃ¡ Ä‘á»™ tin cáº­y
3. Format response thÃ¢n thiá»‡n, dá»… hiá»ƒu

RAW ANSWER:
{raw_answer}

RAG CONTEXT:
{chr(10).join(rag_context)}

Tráº£ lá»i báº±ng JSON format:
{{
    "verification_score": 1-10,
    "confidence": "high|medium|low",
    "final_response": "formatted response",
    "suggestions": ["optional follow-up suggestions"]
}}"""
        )
        
        request = AgentRequest(
            prompt="XÃ¡c minh vÃ  format cÃ¢u tráº£ lá»i vá» há»c phÃ­ UIT",
            context=context,
            model="deepseek/deepseek-r1:free",
            temperature=0.3,
            max_tokens=500
        )
        
        response = await adapter.generate_response(request)
        
        print(f"âœ… Response Formatter Agent Response:")
        print(f"Model: {response.model_used}")
        print(f"Formatted Response: {response.content}")
        print(f"Tokens: {response.tokens_used}")
        
        await adapter.close()
        return True
        
    except Exception as e:
        print(f"âŒ Response Formatter Agent Error: {e}")
        return False


async def main():
    """Run all optimized agent tests."""
    print("ğŸš€ Testing Optimized 3-Agent Pipeline")
    print("=" * 60)
    print("Pipeline: SmartPlanner â†’ Answer â†’ ResponseFormatter")
    print("Cost Savings: ~40% fewer LLM calls compared to 5-agent pipeline")
    print("=" * 60)
    
    tests = [
        ("Smart Planner Agent", test_smart_planner_agent),
        ("Answer Agent", test_answer_agent),
        ("Response Formatter Agent", test_response_formatter_agent),
    ]
    
    results = []
    
    for name, test_func in tests:
        try:
            print(f"\n{'='*20} {name} {'='*20}")
            result = await test_func()
            results.append((name, result))
        except Exception as e:
            print(f"âŒ {name} failed with exception: {e}")
            results.append((name, False))
    
    print("\n" + "=" * 60)
    print("ğŸ“Š FINAL RESULTS:")
    print("=" * 60)
    
    passed = 0
    for name, result in results:
        status = "âœ… PASSED" if result else "âŒ FAILED"
        print(f"{name}: {status}")
        if result:
            passed += 1
    
    print(f"\nOverall: {passed}/{len(results)} agents working correctly")
    
    if passed == len(results):
        print("ğŸ‰ ALL OPTIMIZED AGENTS WORKING PERFECTLY!")
    else:
        print("âš ï¸  Some agents need attention.")


if __name__ == "__main__":
    asyncio.run(main())
