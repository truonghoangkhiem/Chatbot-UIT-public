#!/usr/bin/env python3
"""
Test th·ª±c t·∫ø chatbot v·ªõi c√¢u h·ªèi v·ªÅ quy ch·∫ø ƒë√†o t·∫°o UIT
Xem c√°ch LLM s·ª≠ d·ª•ng RAG v√† Knowledge Graph
"""

import asyncio
import sys
import os
from pathlib import Path

# Add parent directory to path FIRST
sys.path.insert(0, str(Path(__file__).parent.parent))

# Setup rag_services path
rag_services_path = Path(__file__).parent.parent.parent / "rag_services"
sys.path.insert(0, str(rag_services_path))

# Load environment
from dotenv import load_dotenv
env_path = Path(__file__).parent.parent / ".env"
load_dotenv(env_path, override=True)

# ƒê·∫£m b·∫£o password Neo4j ƒë√∫ng
if not os.getenv("NEO4J_PASSWORD"):
    os.environ["NEO4J_PASSWORD"] = "password"


def print_separator(title):
    print(f"\n{'='*70}")
    print(f"üß™ {title}")
    print(f"{'='*70}")


async def test_real_questions():
    """Test v·ªõi c√¢u h·ªèi th·ª±c t·∫ø"""
    
    print("\n" + "üöÄ"*35)
    print("    REAL CHATBOT TEST - UIT Quy ch·∫ø ƒë√†o t·∫°o")
    print("üöÄ"*35)
    
    # Import container
    from app.core.container import get_container
    
    print_separator("Initializing Services")
    
    try:
        container = get_container()
        orchestrator = container.get_multi_agent_orchestrator()
        print("‚úÖ Orchestrator initialized successfully")
        print(f"   - Graph Reasoning: {'Enabled' if orchestrator.graph_reasoning_agent else 'Disabled'}")
        print(f"   - IRCoT: {'Enabled' if orchestrator.ircot_config.enabled else 'Disabled'}")
    except Exception as e:
        print(f"‚ùå Failed to initialize: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # C√°c c√¢u h·ªèi test
    test_questions = [
        # C√¢u h·ªèi ƒë∆°n gi·∫£n - n√™n d√πng RAG
        "ƒêi·ªÅu ki·ªán ƒë·ªÉ sinh vi√™n ƒë∆∞·ª£c x√©t t·ªët nghi·ªáp l√† g√¨?",
        
        # C√¢u h·ªèi v·ªÅ quy ƒë·ªãnh c·ª• th·ªÉ
        # "Sinh vi√™n c·∫ßn ƒë·∫°t bao nhi√™u t√≠n ch·ªâ ƒë·ªÉ t·ªët nghi·ªáp?",
        
        # C√¢u h·ªèi v·ªÅ m·ªëi quan h·ªá - n√™n d√πng KG
        # "ƒêi·ªÅu 14 quy ƒë·ªãnh nh·ªØng g√¨ v·ªÅ ƒëƒÉng k√Ω h·ªçc ph·∫ßn?",
    ]
    
    for i, question in enumerate(test_questions, 1):
        print_separator(f"Question {i}: {question[:50]}...")
        print(f"\nüìù Full question: {question}\n")
        
        try:
            # G·ªçi orchestrator
            from app.core.domain import OrchestrationRequest
            
            request = OrchestrationRequest(
                query=question,
                conversation_id=f"test_{i}",
                user_id="test_user"
            )
            
            print("‚è≥ Processing query...")
            print("-" * 50)
            
            result = await orchestrator.process_query(request)
            
            print("\n" + "="*50)
            print("üìä RESULT ANALYSIS")
            print("="*50)
            
            # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ sources
            if hasattr(result, 'metadata') and result.metadata:
                meta = result.metadata
                print(f"\nüîç Data Sources Used:")
                
                # Ki·ªÉm tra RAG context
                if 'rag_context' in meta:
                    rag = meta['rag_context']
                    print(f"   üìö RAG: {len(rag.get('chunks', []))} chunks retrieved")
                    if rag.get('chunks'):
                        print(f"      - Top chunk score: {rag['chunks'][0].get('score', 'N/A')}")
                
                # Ki·ªÉm tra KG context  
                if 'kg_context' in meta:
                    kg = meta['kg_context']
                    print(f"   üîó Knowledge Graph: {kg.get('nodes_found', 0)} nodes")
                    print(f"      - Query type: {kg.get('query_type', 'N/A')}")
                    print(f"      - Confidence: {kg.get('confidence', 'N/A')}")
                
                # Planning info
                if 'planning' in meta:
                    plan = meta['planning']
                    print(f"\nüìã Smart Planner Decision:")
                    print(f"   - Complexity: {plan.get('complexity', 'N/A')}")
                    print(f"   - Use RAG: {plan.get('use_rag', 'N/A')}")
                    print(f"   - Use KG: {plan.get('use_kg', 'N/A')}")
                    print(f"   - Query type: {plan.get('query_type', 'N/A')}")
            
            # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi
            print(f"\nüí¨ ANSWER:")
            print("-" * 50)
            answer = result.response if hasattr(result, 'response') else str(result)
            # Gi·ªõi h·∫°n ƒë·ªô d√†i hi·ªÉn th·ªã
            if len(answer) > 1000:
                print(answer[:1000] + "\n... [truncated]")
            else:
                print(answer)
            print("-" * 50)
            
            # Hi·ªÉn th·ªã citations n·∫øu c√≥
            if hasattr(result, 'citations') and result.citations:
                print(f"\nüìé Citations: {len(result.citations)}")
                for c in result.citations[:3]:
                    print(f"   - {c}")
                    
        except Exception as e:
            print(f"‚ùå Error processing question: {e}")
            import traceback
            traceback.print_exc()
    
    print_separator("TEST COMPLETED")


if __name__ == "__main__":
    asyncio.run(test_real_questions())
