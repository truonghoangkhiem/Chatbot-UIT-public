#!/usr/bin/env python3
"""
Benchmark th·ªùi gian x·ª≠ l√Ω t·ª´ng ph·∫ßn c·ªßa pipeline
"""

import asyncio
import sys
import os
import time
from pathlib import Path
from datetime import datetime

# Setup paths
sys.path.insert(0, str(Path(__file__).parent.parent))
rag_path = Path(__file__).parent.parent.parent / "rag_services"
sys.path.insert(0, str(rag_path))

from dotenv import load_dotenv
load_dotenv(Path(__file__).parent.parent / ".env", override=True)

if not os.getenv("NEO4J_PASSWORD"):
    os.environ["NEO4J_PASSWORD"] = "password"

import logging
logging.basicConfig(level=logging.WARNING)

import httpx
from neo4j import GraphDatabase


async def benchmark_rag():
    """Benchmark RAG search"""
    print("\nüìö RAG Search:")
    start = time.time()
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/v1/search",
            json={"query": "ƒëi·ªÅu ki·ªán ƒëƒÉng k√Ω h·ªçc ph·∫ßn", "top_k": 5},
            timeout=30
        )
    elapsed = time.time() - start
    
    if response.status_code == 200:
        data = response.json()
        print(f"   Time: {elapsed:.2f}s")
        print(f"   Documents: {data.get('total_hits', 0)}")
        print(f"   Internal latency: {data.get('latency_ms', 0):.0f}ms")
    return elapsed


def benchmark_kg():
    """Benchmark KG search"""
    print("\nüîó Knowledge Graph Search:")
    start = time.time()
    
    driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", os.getenv('NEO4J_PASSWORD', 'password')))
    with driver.session() as session:
        result = session.run("""
            MATCH (a:Article)
            WHERE toLower(a.title) CONTAINS 'ƒëƒÉng k√Ω' 
               OR toLower(a.full_text) CONTAINS 'ƒëƒÉng k√Ω h·ªçc ph·∫ßn'
            RETURN a.title as title
            LIMIT 5
        """)
        articles = list(result)
    driver.close()
    
    elapsed = time.time() - start
    print(f"   Time: {elapsed:.2f}s")
    print(f"   Articles: {len(articles)}")
    return elapsed


async def benchmark_llm():
    """Benchmark LLM call"""
    print("\nü§ñ LLM API Call:")
    
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        print("   ‚ö†Ô∏è  No OPENROUTER_API_KEY found")
        return 3.0  # Estimate
    
    start = time.time()
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": "openai/gpt-4o-mini",
                "messages": [{"role": "user", "content": "Xin ch√†o, b·∫°n l√† ai?"}],
                "max_tokens": 100
            },
            timeout=30
        )
    elapsed = time.time() - start
    
    if response.status_code == 200:
        print(f"   Time: {elapsed:.2f}s")
    else:
        print(f"   Error: {response.status_code}")
    
    return elapsed


async def test_parallel():
    """Test parallel execution"""
    print("\n" + "="*70)
    print("üîÑ PARALLEL VS SEQUENTIAL TEST")
    print("="*70)
    
    async def async_rag():
        start = time.time()
        async with httpx.AsyncClient() as client:
            await client.post(
                "http://localhost:8000/v1/search",
                json={"query": "ƒëi·ªÅu ki·ªán ƒëƒÉng k√Ω h·ªçc ph·∫ßn", "top_k": 5},
                timeout=30
            )
        return time.time() - start
    
    async def async_kg():
        start = time.time()
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, _sync_kg)
        return time.time() - start
    
    def _sync_kg():
        driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", os.getenv('NEO4J_PASSWORD', 'password')))
        with driver.session() as session:
            result = session.run("MATCH (a:Article) RETURN a.title LIMIT 5")
            list(result)
        driver.close()
    
    # Sequential
    print("\nüîÄ Sequential (RAG then KG):")
    seq_start = time.time()
    rag_t = await async_rag()
    kg_t = await async_kg()
    seq_time = time.time() - seq_start
    print(f"   RAG: {rag_t:.2f}s + KG: {kg_t:.2f}s = {seq_time:.2f}s")
    
    # Parallel
    print("\n‚ö° Parallel (RAG + KG together):")
    par_start = time.time()
    results = await asyncio.gather(async_rag(), async_kg())
    par_time = time.time() - par_start
    print(f"   RAG: {results[0]:.2f}s, KG: {results[1]:.2f}s (parallel) = {par_time:.2f}s")
    
    speedup = seq_time / par_time if par_time > 0 else 1
    print(f"\nüìä Speedup: {speedup:.1f}x faster with parallel")
    
    return seq_time, par_time


async def main():
    print("\n" + "üöÄ"*35)
    print("    PIPELINE TIMING BENCHMARK")
    print("üöÄ"*35)
    print(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    print("\n" + "="*70)
    print("üî¨ COMPONENT BENCHMARKS")
    print("="*70)
    
    # Individual components
    rag_time = await benchmark_rag()
    kg_time = benchmark_kg()
    llm_time = await benchmark_llm()
    
    print("\n" + "="*70)
    print("üìä COMPONENT SUMMARY")
    print("="*70)
    print(f"\n   RAG Search:      {rag_time:.2f}s")
    print(f"   KG Search:       {kg_time:.2f}s")
    print(f"   LLM Call:        {llm_time:.2f}s")
    print(f"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    
    sequential = rag_time + kg_time + llm_time * 2  # 2 LLM calls
    parallel = max(rag_time, kg_time) + llm_time * 2
    
    print(f"   If Sequential:   {sequential:.2f}s")
    print(f"   If Parallel:     {parallel:.2f}s")
    
    # Parallel test
    seq_t, par_t = await test_parallel()
    
    print("\n" + "="*70)
    print("üìà ANALYSIS")
    print("="*70)
    
    print("\nüîç Bottleneck Analysis:")
    
    if rag_time > 1:
        print(f"   ‚ö†Ô∏è  RAG is slow ({rag_time:.1f}s)")
        print(f"      - Weaviate vector search latency")
        print(f"      - Reranking may be adding time")
    else:
        print(f"   ‚úÖ RAG is fast ({rag_time:.1f}s)")
    
    if kg_time > 0.5:
        print(f"   ‚ö†Ô∏è  KG is slow ({kg_time:.1f}s)")
    else:
        print(f"   ‚úÖ KG is fast ({kg_time:.1f}s)")
    
    if llm_time > 3:
        print(f"   ‚ö†Ô∏è  LLM is slow ({llm_time:.1f}s)")
        print(f"      - OpenRouter API latency")
        print(f"      - Consider caching or faster model")
    else:
        print(f"   ‚úÖ LLM is acceptable ({llm_time:.1f}s)")
    
    print(f"\n‚è±Ô∏è  Estimated Full Query Time:")
    print(f"   - Planning (1 LLM):     ~{llm_time:.1f}s")
    print(f"   - RAG + KG (parallel):  ~{max(rag_time, kg_time):.1f}s")
    print(f"   - Answer (1 LLM):       ~{llm_time:.1f}s")
    print(f"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    print(f"   TOTAL (optimal):        ~{max(rag_time, kg_time) + llm_time * 2:.1f}s")
    
    actual_test_time = 41.68  # From earlier test
    print(f"\n   Actual observed:        ~{actual_test_time:.1f}s")
    
    if actual_test_time > parallel * 1.5:
        print(f"\n   ‚ùå Actual is much slower than expected!")
        print(f"      Possible issues:")
        print(f"      - RAG queries may not be parallel")
        print(f"      - Multiple LLM calls happening")
        print(f"      - Cold start / initialization overhead")
    
    print("\n" + "="*70)
    print("‚úÖ BENCHMARK COMPLETE")
    print("="*70)


if __name__ == "__main__":
    asyncio.run(main())
